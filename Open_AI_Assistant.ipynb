{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Start"
      ],
      "metadata": {
        "id": "ymVIusoNohqc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhKiKV5i3Scq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"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\""
      ],
      "metadata": {
        "id": "AbiiKLnkc4Vv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai --upgrade openai"
      ],
      "metadata": {
        "id": "UAm9dxc9psZg",
        "outputId": "33473314-2e89-46ad-e724-0c593b2c47e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m163.8/225.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.10.0 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))"
      ],
      "metadata": {
        "id": "vV4TIX52dr4D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", api_key))"
      ],
      "metadata": {
        "id": "qyxOb5USogqa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "show_json(assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "XnNB0QDwdlRJ",
        "outputId": "3c17f441-fd6f-42c2-c819-4ecef2367df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'asst_XLJqjrSX1ZQZGONBSKtWPrpr',\n",
              " 'created_at': 1706552645,\n",
              " 'description': None,\n",
              " 'file_ids': [],\n",
              " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
              " 'metadata': {},\n",
              " 'model': 'gpt-4-1106-preview',\n",
              " 'name': 'Math Tutor',\n",
              " 'object': 'assistant',\n",
              " 'tools': []}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "dzsvJHlUd49Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
        ")\n",
        "show_json(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "l2otHNkFeC7q",
        "outputId": "6a39fa61-a06c-4c4f-84a6-dbff12cc7cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_2t4bOnZfOm1vTGhg3FfPDXHl',\n",
              " 'assistant_id': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1706552735,\n",
              " 'file_ids': [],\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        ")\n",
        "show_json(run)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "8Pbq0bS0eXMm",
        "outputId": "02b65ccc-e4a1-4770-d090-9702679b8477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'run_zDRfIyln6aTtkDIXGyEWeutc',\n",
              " 'assistant_id': 'asst_XLJqjrSX1ZQZGONBSKtWPrpr',\n",
              " 'cancelled_at': None,\n",
              " 'completed_at': None,\n",
              " 'created_at': 1706552818,\n",
              " 'expires_at': 1706553418,\n",
              " 'failed_at': None,\n",
              " 'file_ids': [],\n",
              " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
              " 'last_error': None,\n",
              " 'metadata': {},\n",
              " 'model': 'gpt-4-1106-preview',\n",
              " 'object': 'thread.run',\n",
              " 'required_action': None,\n",
              " 'started_at': None,\n",
              " 'status': 'queued',\n",
              " 'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL',\n",
              " 'tools': [],\n",
              " 'usage': None}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def wait_on_run(run, thread):\n",
        "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id,\n",
        "        )\n",
        "        time.sleep(0.5)\n",
        "    return run\n"
      ],
      "metadata": {
        "id": "QqTQYxVrepKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wait_on_run(run, thread)\n",
        "show_json(run)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "o02pQq79ezCs",
        "outputId": "513070e2-ea5f-4ca8-bd28-a75156145c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'run_zDRfIyln6aTtkDIXGyEWeutc',\n",
              " 'assistant_id': 'asst_XLJqjrSX1ZQZGONBSKtWPrpr',\n",
              " 'cancelled_at': None,\n",
              " 'completed_at': 1706552821,\n",
              " 'created_at': 1706552818,\n",
              " 'expires_at': None,\n",
              " 'failed_at': None,\n",
              " 'file_ids': [],\n",
              " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
              " 'last_error': None,\n",
              " 'metadata': {},\n",
              " 'model': 'gpt-4-1106-preview',\n",
              " 'object': 'thread.run',\n",
              " 'required_action': None,\n",
              " 'started_at': 1706552818,\n",
              " 'status': 'completed',\n",
              " 'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL',\n",
              " 'tools': [],\n",
              " 'usage': {'completion_tokens': 34, 'prompt_tokens': 57, 'total_tokens': 91}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "show_json(messages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "H-oXMF3lfDIH",
        "outputId": "bc210341-b7bc-4c4b-e9a3-e3ba6447c35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'data': [{'id': 'msg_khnlECPNl7tdiCBpiE4z83Ay',\n",
              "   'assistant_id': 'asst_XLJqjrSX1ZQZGONBSKtWPrpr',\n",
              "   'content': [{'text': {'annotations': [],\n",
              "      'value': 'Yes, subtract 11 from both sides to get `3x = 3`, then divide both sides by 3 to find `x = 1`.'},\n",
              "     'type': 'text'}],\n",
              "   'created_at': 1706552819,\n",
              "   'file_ids': [],\n",
              "   'metadata': {},\n",
              "   'object': 'thread.message',\n",
              "   'role': 'assistant',\n",
              "   'run_id': 'run_zDRfIyln6aTtkDIXGyEWeutc',\n",
              "   'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL'},\n",
              "  {'id': 'msg_2t4bOnZfOm1vTGhg3FfPDXHl',\n",
              "   'assistant_id': None,\n",
              "   'content': [{'text': {'annotations': [],\n",
              "      'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
              "     'type': 'text'}],\n",
              "   'created_at': 1706552735,\n",
              "   'file_ids': [],\n",
              "   'metadata': {},\n",
              "   'object': 'thread.message',\n",
              "   'role': 'user',\n",
              "   'run_id': None,\n",
              "   'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL'}],\n",
              " 'object': 'list',\n",
              " 'first_id': 'msg_khnlECPNl7tdiCBpiE4z83Ay',\n",
              " 'last_id': 'msg_2t4bOnZfOm1vTGhg3FfPDXHl',\n",
              " 'has_more': False}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a message to append to our thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id, role=\"user\", content=\"Could you explain this to me?\"\n",
        ")\n",
        "\n",
        "# Execute our run\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for completion\n",
        "wait_on_run(run, thread)\n",
        "\n",
        "# Retrieve all the messages added after our last user message\n",
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread.id, order=\"asc\", after=message.id\n",
        ")\n",
        "show_json(messages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "RLZ4zLEzjbMT",
        "outputId": "cf7328cd-6749-435f-9c3d-720464d6953e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'data': [{'id': 'msg_4REcn08FCfW9H01aTjaU1q85',\n",
              "   'assistant_id': 'asst_XLJqjrSX1ZQZGONBSKtWPrpr',\n",
              "   'content': [{'text': {'annotations': [],\n",
              "      'value': \"Certainly! To solve `3x + 11 = 14`, follow these steps:\\n\\n1. Subtract 11 from both sides: `3x + 11 - 11 = 14 - 11` to isolate the term with x on one side, which results in `3x = 3`.\\n2. Divide both sides by 3: `3x / 3 = 3 / 3` to solve for x, which simplifies to `x = 1`.\\n\\nNow you've solved for x, which is 1.\"},\n",
              "     'type': 'text'}],\n",
              "   'created_at': 1706554148,\n",
              "   'file_ids': [],\n",
              "   'metadata': {},\n",
              "   'object': 'thread.message',\n",
              "   'role': 'assistant',\n",
              "   'run_id': 'run_BLzAdUQbQfvwrsHYvNBvNlNH',\n",
              "   'thread_id': 'thread_3vIApBTL5IM14zDkDkkoaFqL'}],\n",
              " 'object': 'list',\n",
              " 'first_id': 'msg_4REcn08FCfW9H01aTjaU1q85',\n",
              " 'last_id': 'msg_4REcn08FCfW9H01aTjaU1q85',\n",
              " 'has_more': False}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Math_assistant_id = assistant.id\n",
        "\n",
        "thread2 = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "kKc1rV_gsl84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trying my own assistant"
      ],
      "metadata": {
        "id": "A4_z9lNL0dLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp_intruct = \"\"\"\n",
        "you are an expert in Supply chain planning, acting as a supply planner. you should consider the excel file as a database to retrieve data to answer\n",
        "ueer queries. All Questio Answer questions briefly, in a sentence or less.\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IuCGuRWf0wPL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant1 = client.beta.assistants.create(\n",
        "      name=\"Supply Planner\",\n",
        "    instructions=\"you are an expert in Supply chain planning, acting as a supply planner. you should consider Answer questions briefly, in a sentence or less.\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "show_json(assistant1)\n",
        "\n"
      ],
      "metadata": {
        "id": "3KV-MPph0gW6",
        "outputId": "0841e4b3-075f-46a0-a865-d51a9e61d924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'asst_pn3Cn8qknsyDfv19uLiktQvN',\n",
              " 'created_at': 1706814040,\n",
              " 'description': None,\n",
              " 'file_ids': [],\n",
              " 'instructions': 'you are an expert in Supply chain planning, acting as a supply planner. you should consider Answer questions briefly, in a sentence or less.',\n",
              " 'metadata': {},\n",
              " 'model': 'gpt-4-1106-preview',\n",
              " 'name': 'Supply Planner',\n",
              " 'object': 'assistant',\n",
              " 'tools': []}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread1 = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "tQCzNE150gzT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message1 = client.beta.threads.messages.create(\n",
        "    thread_id = thread1.id,\n",
        "    role = \"user\",\n",
        "    content = \"explain the steps to create a production plan for an sku basis opening stock and monthwise sales forecast. sku has an inventory norm of 30 days. There is no production constraint\",\n",
        "                  )\n",
        "show_json(message1)"
      ],
      "metadata": {
        "id": "tbcDfDJ83vUh",
        "outputId": "5adeac7b-8adb-4ac3-f767-5b45658a2bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_DEMQG80CTPTdMoUMOCg3p362',\n",
              " 'assistant_id': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'explain the steps to create a production plan for an sku basis opening stock and monthwise sales forecast. sku has an inventory norm of 30 days. There is no production constraint'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1706814045,\n",
              " 'file_ids': [],\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'thread_id': 'thread_uPQQacBq4nlsQiW64HT8UDkq'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "    assistant_id = assistant1.id,\n",
        "    thread_id = thread1.id\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "xqSKdv-r4VU8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def wait_on_run(run, thread):\n",
        "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id,\n",
        "        )\n",
        "        time.sleep(0.5)\n",
        "    return run\n"
      ],
      "metadata": {
        "id": "iWov71bF42m-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id = thread1.id\n",
        ")"
      ],
      "metadata": {
        "id": "ouR5Oqgs5UtF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_json(messages)"
      ],
      "metadata": {
        "id": "OdAbO96b5aqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a funstion to extract message content of open ai assistant\n",
        "\n",
        "def show_as_chat(messages):\n",
        "  \"\"\"\n",
        "  Extracts the content of messages from an OpenAI chat history.\n",
        "\n",
        "  Args:\n",
        "    messages: A list of OpenAI message objects.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings containing the message content.\n",
        "  \"\"\"\n",
        "\n",
        "  message_content = []\n",
        "  message_content2 = \"\"\n",
        "  for message in messages:   # to show old messgaes first, we need to traverse the list in reverse order\n",
        "  #  if message.role == \"assistant\":\n",
        "  #    message_content.append(message.content)\n",
        "\n",
        "  #     print (message.role , \"\\n\")\n",
        "  #     print (message.content)\n",
        "     message_content.append(message.content[0].text.value)\n",
        "     message_content2 += message.role + ' : \\n' + message.content[0].text.value + '\\n\\n\\n'\n",
        "\n",
        "\n",
        "  return message_content2\n",
        "\n",
        "message_content = show_as_chat(messages)\n",
        "print(message_content)"
      ],
      "metadata": {
        "id": "Z3lMlrU5Dbze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwyuYmk6Mu8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}